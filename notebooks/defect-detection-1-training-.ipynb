{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial #1: Train an image classification model with Azure Machine Learning accessing a Data Labeling Dataset export\n",
    "\n",
    "In this tutorial, you train a machine learning model on remote compute resources. You'll use the training and deployment workflow for Azure Machine Learning service (preview) in a Python Jupyter notebook.  You can then use the notebook as a template to train your own machine learning model with your own data. This tutorial is **part one of a two-part tutorial series**.  \n",
    "\n",
    "Learn how to:\n",
    "\n",
    "> * Set up your development environment\n",
    "> * Access and examine the data\n",
    "> * Train a simple logistic regression model on a remote cluster\n",
    "> * Review training results, find and register the best model\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "See prerequisites in the [Azure Machine Learning documentation](https://docs.microsoft.com/azure/machine-learning/service/tutorial-train-models-with-aml#prerequisites)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up your development environment\n",
    "\n",
    "All the setup for your development work can be accomplished in a Python notebook.  Setup includes:\n",
    "\n",
    "* Importing Python packages\n",
    "* Connecting to a workspace to enable communication between your local computer and remote resources\n",
    "* Creating an experiment to track all your runs\n",
    "* Creating a remote compute target to use for training\n",
    "\n",
    "### Import packages\n",
    "\n",
    "Import Python packages you need in this session. Also display the Azure Machine Learning SDK version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": [
     "check version"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.76\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to workspace\n",
    "\n",
    "Create a workspace object from the existing workspace. `Workspace.from_config()` reads the file **config.json** and loads the details into an object named `ws`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": [
     "load workspace"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ailabml\twestus2\tai-lab\n"
     ]
    }
   ],
   "source": [
    "# load workspace configuration from the config.json file in the current folder.\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create experiment\n",
    "\n",
    "Create an experiment to track the runs in your workspace. A workspace can have muliple experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": [
     "create experiment"
    ]
   },
   "outputs": [],
   "source": [
    "experiment_name = 'ai-lab-defect-detection'\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Attach existing compute resource\n",
    "By using Azure Machine Learning Compute, a managed service, data scientists can train machine learning models on clusters of Azure virtual machines. Examples include VMs with GPU support. In this tutorial, you create Azure Machine Learning Compute as your training environment. The code below creates the compute clusters for you if they don't already exist in your workspace.\n",
    "\n",
    "**Creation of compute takes approximately 5 minutes.** If the AmlCompute with that name is already in your workspace the code will skip the creation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": [
     "create mlc",
     "amlcompute"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target: cpu-cluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpu-cluster\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print(\"found compute target: \" + compute_name)\n",
    "else:\n",
    "    print(\"creating new compute target...\")\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have the necessary packages and compute resources to train a model in the cloud. \n",
    "\n",
    "## Explore data\n",
    "\n",
    "Before you train a model, you need to understand the data that you are using to train it. In this section you learn how to:\n",
    "\n",
    "* Download the MNIST dataset\n",
    "* Display some sample images\n",
    "\n",
    "### Download the Data Labeling exported Dataset\n",
    "\n",
    "This code retrieves the data as a `TabularDataset` object, which is a subclass of `Dataset`. A `TabularDataset` references images and their labels and confidence. The class provides you with the ability to download or mount the files to your compute by creating a reference to the data source location. Additionally, you register the Dataset to your workspace for easy retrieval during training.\n",
    "\n",
    "Follow the [how-to](https://aka.ms/azureml/howto/createdatasets) to learn more about Datasets and their usage in the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the azureml-contrib-dataset package\n",
    "%pip install azureml-contrib-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [02:57<00:00,  5.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 65536)\n",
      "(27,)\n",
      "(7, 65536)\n",
      "(7,)\n",
      "Train a logistic regression model with regularization rate of 0.5\n",
      "Predict the test set\n",
      "Classification report for - \n",
      "LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
      "          n_jobs=None, penalty='l2', random_state=12, solver='liblinear',\n",
      "          tol=0.0001, verbose=0, warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      broken       0.67      0.67      0.67         3\n",
      "  not_broken       0.75      0.75      0.75         4\n",
      "\n",
      "   micro avg       0.71      0.71      0.71         7\n",
      "   macro avg       0.71      0.71      0.71         7\n",
      "weighted avg       0.71      0.71      0.71         7\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================================\n",
    "# This code is just to demo/debug what we will do in the train.py script defined below\n",
    "# ====================================================================================\n",
    "\n",
    "#\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import svm, metrics, datasets\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore\n",
    "from azureml.contrib.dataset import Dataset\n",
    "\n",
    "def load_image_files(dimension=(256, 256)):\n",
    "\n",
    "    # get dataset\n",
    "    subscription_id = 'c5ec24ce-9c5f-4da2-bf12-9ca8e9758d60'\n",
    "    resource_group = 'ai-lab'\n",
    "    workspace_name = 'ailabml'\n",
    "    workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "    ds = Dataset.get_by_name(workspace, name='Light Bulbs-2019-12-08 00:35:33')\n",
    "    df = ds.to_pandas_dataframe()\n",
    "\n",
    "    # Images\n",
    "    descr = \"Defect Detection Dataset\"\n",
    "    images = []\n",
    "    flat_data = []\n",
    "    target = []\n",
    "    categories = set()\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        si = df.loc[i].image_url.to_pod()\n",
    "        if i == 0:\n",
    "            datastore = Datastore.get(workspace, si['arguments']['datastoreName'])\n",
    "        categories.add(df.loc[i].label[0])\n",
    "        datastore.download(target_path='.',prefix=si['resourceIdentifier'],overwrite=True,show_progress=False)\n",
    "        img = imread(si['resourceIdentifier'], as_gray=True)\n",
    "        img_resized = resize(img, dimension, anti_aliasing=True, mode='reflect')\n",
    "        flat_data.append(img_resized.flatten()) \n",
    "        images.append(img_resized)\n",
    "        target.append(df.loc[i].label[0])\n",
    "\n",
    "    categories = list(categories)\n",
    "    flat_data = np.array(flat_data)\n",
    "    target = np.array(target)\n",
    "    images = np.array(images)\n",
    "\n",
    "    return Bunch(data=flat_data,\n",
    "                 target=target,\n",
    "                 target_names=categories,\n",
    "                 images=images,\n",
    "                 DESCR=descr)\n",
    "\n",
    "# load train and test set\n",
    "image_dataset = load_image_files()\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    image_dataset.data, image_dataset.target, test_size=0.2,random_state=12)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep = '\\n')\n",
    "\n",
    "print('Train a logistic regression model with regularization rate of', 0.5)\n",
    "clf = LogisticRegression(C=1.0/0.5, solver=\"liblinear\", multi_class=\"auto\", random_state=12)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Predict the test set')\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for - \\n{}:\\n{}\\n\".format(\n",
    "    clf, metrics.classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on a remote cluster\n",
    "\n",
    "For this task, submit the job to the remote training cluster you set up earlier.  To submit a job you:\n",
    "* Create a directory\n",
    "* Create a training script\n",
    "* Create an estimator object\n",
    "* Submit the job \n",
    "\n",
    "### Create a directory\n",
    "\n",
    "Create a directory to deliver the necessary code from your computer to the remote resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), \"scripts\")\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training script\n",
    "\n",
    "To submit the job to the cluster, first create a training script. Run the following code to create the training script called `train.py` in the directory you just created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/azmnt/code/Users/aldelar/ai-lab/scripts/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "#\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import svm, metrics, datasets\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore\n",
    "from azureml.contrib.dataset import Dataset\n",
    "\n",
    "def load_image_files(dimension=(256, 256)):\n",
    "    \n",
    "    # get dataset (online run)\n",
    "    run = Run.get_context()\n",
    "    ds = run.input_datasets['Light Bulbs-2019-12-08 00:35:33']\n",
    "    \n",
    "    # get dataset (offline run)\n",
    "    #subscription_id = 'c5ec24ce-9c5f-4da2-bf12-9ca8e9758d60'\n",
    "    #resource_group = 'ai-lab'\n",
    "    #workspace_name = 'ailabml'\n",
    "    #workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "    #ds = Dataset.get_by_name(workspace, name='Light Bulbs-2019-12-08 00:35:33')\n",
    "    \n",
    "    # dataset to dataframe\n",
    "    df = ds.to_pandas_dataframe()\n",
    "\n",
    "    # Images\n",
    "    descr = \"Defect Detection Dataset\"\n",
    "    images = []\n",
    "    flat_data = []\n",
    "    target = []\n",
    "    categories = set()\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        si = df.loc[i].image_url.to_pod()\n",
    "        if i == 0:\n",
    "            datastore = Datastore.get(workspace, si['arguments']['datastoreName'])\n",
    "        categories.add(df.loc[i].label[0])\n",
    "        datastore.download(target_path='.',prefix=si['resourceIdentifier'],overwrite=True,show_progress=False)\n",
    "        img = imread(si['resourceIdentifier'], as_gray=True)\n",
    "        img_resized = resize(img, dimension, anti_aliasing=True, mode='reflect')\n",
    "        flat_data.append(img_resized.flatten()) \n",
    "        images.append(img_resized)\n",
    "        target.append(df.loc[i].label[0])\n",
    "\n",
    "    categories = list(categories)\n",
    "    flat_data = np.array(flat_data)\n",
    "    target = np.array(target)\n",
    "    images = np.array(images)\n",
    "\n",
    "    return Bunch(data=flat_data,\n",
    "                 target=target,\n",
    "                 target_names=categories,\n",
    "                 images=images,\n",
    "                 DESCR=descr)\n",
    "\n",
    "# let user feed in 2 parameters, the dataset to mount or download, and the regularization rate of the logistic regression model\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg', default=0.5, help='regularization rate')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# load train and test set\n",
    "image_dataset = load_image_files()\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    image_dataset.data, image_dataset.target, test_size=0.2,random_state=12)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep = '\\n')\n",
    "\n",
    "# get hold of the current run\n",
    "run = Run.get_context()\n",
    "\n",
    "print('Train a logistic regression model with regularization rate of', args.reg)\n",
    "clf = LogisticRegression(C=1.0/args.reg, solver=\"liblinear\", multi_class=\"auto\", random_state=12)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Predict the test set')\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for - \\n{}:\\n{}\\n\".format(\n",
    "    clf, metrics.classification_report(y_test, y_pred)))\n",
    "\n",
    "# calculate accuracy on the prediction\n",
    "acc = np.average(y_pred == y_test)\n",
    "print('Accuracy is', acc)\n",
    "\n",
    "run.log('regularization rate', np.float(args.reg))\n",
    "run.log('accuracy', np.float(acc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=clf, filename='outputs/ai_lab_defect_detection_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the script gets data and saves models:\n",
    "\n",
    "+ The training script reads an argument to find the directory containing the data.  When you submit the job later, you point to the dataset for this argument:\n",
    "`parser.add_argument('--data-folder', type=str, dest='data_folder', help='data directory mounting point')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "+ The training script saves your model into a directory named outputs. <br/>\n",
    "`joblib.dump(value=clf, filename='outputs/sklearn_ai_lab_defect_detection_model.pkl')`<br/>\n",
    "Anything written in this directory is automatically uploaded into your workspace. You'll access your model from this directory later in the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `utils.py` is referenced from the training script to load the dataset correctly.  Copy this script into the script folder so that it can be accessed along with the training script on the remote resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an estimator\n",
    "\n",
    "An estimator object is used to submit the run. Azure Machine Learning has pre-configured estimators for common machine learning frameworks, as well as generic Estimator. Create SKLearn estimator for scikit-learn model, by specifying\n",
    "\n",
    "* The name of the estimator object, `est`\n",
    "* The directory that contains your scripts. All the files in this directory are uploaded into the cluster nodes for execution. \n",
    "* The compute target.  In this case you will use the AmlCompute you created\n",
    "* The training script name, train.py\n",
    "* Parameters required from the training script \n",
    "\n",
    "In this tutorial, the target is AmlCompute. All files in the script folder are uploaded into the cluster nodes for execution. The data_folder is set to use the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# to install required packages\n",
    "env = Environment('my_env')\n",
    "cd = CondaDependencies.create(pip_packages=[\n",
    "    'azureml-contrib-dataset',\n",
    "    'azureml-core',\n",
    "    'azureml-dataprep[pandas,fuse]',\n",
    "    'azureml-dataprep-native',\n",
    "    'numpy',\n",
    "    'pandas',\n",
    "    'scikit-image',\n",
    "    'scikit-learn',\n",
    "    'sklearn',\n",
    "    'tqdm'\n",
    "])\n",
    "\n",
    "env.python.conda_dependencies = cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": [
     "configure estimator"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - If environment_definition or conda_dependencies_file_path is specified, Azure ML will not install any framework related packages on behalf of the user.\n",
      "WARNING - This compute target type doesn't support non-Docker runs; overriding run configuration enable Docker.\n",
      "WARNING - You have specified to install packages in your run. Note that you have overridden Azure ML's installation of the following packages: ['numpy', 'scikit-learn']. We cannot guarantee image build will succeed.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "\n",
    "script_params = {}\n",
    "\n",
    "est = SKLearn(source_directory=script_folder,\n",
    "              script_params=script_params,\n",
    "              compute_target=compute_target,\n",
    "              environment_definition=env,\n",
    "              entry_script='train.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the job to the cluster\n",
    "\n",
    "Run the experiment by submitting the estimator object. And you can navigate to Azure portal to monitor the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": [
     "remote run",
     "amlcompute",
     "scikit-learn"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>ai-lab-defect-detection</td><td>ai-lab-defect-detection_1575935091_504b22a6</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://ml.azure.com/experiments/ai-lab-defect-detection/runs/ai-lab-defect-detection_1575935091_504b22a6?wsid=/subscriptions/c5ec24ce-9c5f-4da2-bf12-9ca8e9758d60/resourcegroups/ai-lab/workspaces/ailabml\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: ai-lab-defect-detection,\n",
       "Id: ai-lab-defect-detection_1575935091_504b22a6,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Starting)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = exp.submit(config=est)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the call is asynchronous, it returns a **Preparing** or **Running** state as soon as the job is started.\n",
    "\n",
    "## Monitor a remote run\n",
    "\n",
    "In total, the first run takes **approximately 10 minutes**. But for subsequent runs, as long as the dependencies (`conda_packages` parameter in the above estimator constructor) don't change, the same image is reused and hence the container start up time is much faster.\n",
    "\n",
    "Here is what's happening while you wait:\n",
    "\n",
    "- **Image creation**: A Docker image is created matching the Python environment specified by the estimator. The image is built and stored in the ACR (Azure Container Registry) associated with your workspace. Image creation and uploading takes **about 5 minutes**. \n",
    "\n",
    "  This stage happens once for each Python environment since the container is cached for subsequent runs.  During image creation, logs are streamed to the run history. You can monitor the image creation progress using these logs.\n",
    "\n",
    "- **Scaling**: If the remote cluster requires more nodes to execute the run than currently available, additional nodes are added automatically. Scaling typically takes **about 5 minutes.**\n",
    "\n",
    "- **Running**: In this stage, the necessary scripts and files are sent to the compute target, then data stores are mounted/copied, then the entry_script is run. While the job is running, stdout and the files in the ./logs directory are streamed to the run history. You can monitor the run's progress using these logs.\n",
    "\n",
    "- **Post-Processing**: The ./outputs directory of the run is copied over to the run history in your workspace so you can access these results.\n",
    "\n",
    "\n",
    "You can check the progress of a running job in multiple ways. This tutorial uses a Jupyter widget as well as a `wait_for_completion` method. \n",
    "\n",
    "### Jupyter widget\n",
    "\n",
    "Watch the progress of the run with a Jupyter widget.  Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": [
     "use notebook widget"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522762f2d0dc4a08acfeaf0fbe8b9a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'NOTSET',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Failed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/ai-lab-defect-detection/runs/ai-lab-defect-detection_1575935091_504b22a6?wsid=/subscriptions/c5ec24ce-9c5f-4da2-bf12-9ca8e9758d60/resourcegroups/ai-lab/workspaces/ailabml\", \"run_id\": \"ai-lab-defect-detection_1575935091_504b22a6\", \"run_properties\": {\"run_id\": \"ai-lab-defect-detection_1575935091_504b22a6\", \"created_utc\": \"2019-12-09T23:44:54.01495Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"f165d986-5f34-4736-93a8-b571e39c9680\", \"AzureML.DerivedImageName\": \"azureml/azureml_d52ec22a82c6605a7e3742b0f8974fc7\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2019-12-09T23:45:53.166968Z\", \"status\": \"Failed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt\": \"https://ailabml2830329216.blob.core.windows.net/azureml/ExperimentRun/dcid.ai-lab-defect-detection_1575935091_504b22a6/azureml-logs/55_azureml-execution-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt?sv=2019-02-02&sr=b&sig=7EG8hl4wLlexsQHPLwEb%2BMFOh5G%2BNMeMC%2Bul7D8zGNY%3D&st=2019-12-09T23%3A35%3A58Z&se=2019-12-10T07%3A45%3A58Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt\": \"https://ailabml2830329216.blob.core.windows.net/azureml/ExperimentRun/dcid.ai-lab-defect-detection_1575935091_504b22a6/azureml-logs/65_job_prep-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt?sv=2019-02-02&sr=b&sig=IbFS7ibe4aHCQX7m2njkdo%2FOvepgKHvrCqSyxOQ%2BYM4%3D&st=2019-12-09T23%3A35%3A58Z&se=2019-12-10T07%3A45%3A58Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://ailabml2830329216.blob.core.windows.net/azureml/ExperimentRun/dcid.ai-lab-defect-detection_1575935091_504b22a6/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=Bo5WXja%2BUgktW9cvgnmg7gCXrJF0oGRy8i9qEOdUxQM%3D&st=2019-12-09T23%3A35%3A58Z&se=2019-12-10T07%3A45%3A58Z&sp=r\", \"azureml-logs/75_job_post-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt\": \"https://ailabml2830329216.blob.core.windows.net/azureml/ExperimentRun/dcid.ai-lab-defect-detection_1575935091_504b22a6/azureml-logs/75_job_post-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt?sv=2019-02-02&sr=b&sig=Tz4B4j%2FIc1B%2BFVnW31oud8tp6qycqiipFBtAoXNBVn8%3D&st=2019-12-09T23%3A35%3A58Z&se=2019-12-10T07%3A45%3A58Z&sp=r\", \"azureml-logs/process_info.json\": \"https://ailabml2830329216.blob.core.windows.net/azureml/ExperimentRun/dcid.ai-lab-defect-detection_1575935091_504b22a6/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=YMPcCBjrrTukHPrdGX8O1WkrlPcZBNYkLyOBDd%2B8aXk%3D&st=2019-12-09T23%3A35%3A58Z&se=2019-12-10T07%3A45%3A58Z&sp=r\", \"azureml-logs/process_status.json\": \"https://ailabml2830329216.blob.core.windows.net/azureml/ExperimentRun/dcid.ai-lab-defect-detection_1575935091_504b22a6/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=0OQO6SW24ZsQBtOEdWasdcgt2mhQsCh%2F%2FAkZDNjCqbI%3D&st=2019-12-09T23%3A35%3A58Z&se=2019-12-10T07%3A45%3A58Z&sp=r\", \"logs/azureml/139_azureml.log\": \"https://ailabml2830329216.blob.core.windows.net/azureml/ExperimentRun/dcid.ai-lab-defect-detection_1575935091_504b22a6/logs/azureml/139_azureml.log?sv=2019-02-02&sr=b&sig=s3ZLmMQpO0c1xZFWXoNJ7b3Cn%2FdtvLWdq%2BKn90HNjhw%3D&st=2019-12-09T23%3A35%3A58Z&se=2019-12-10T07%3A45%3A58Z&sp=r\", \"logs/azureml/azureml.log\": \"https://ailabml2830329216.blob.core.windows.net/azureml/ExperimentRun/dcid.ai-lab-defect-detection_1575935091_504b22a6/logs/azureml/azureml.log?sv=2019-02-02&sr=b&sig=lo6F4HV%2BO%2BavgXRkf1gTQqMzcrRgUHvNDmbGxEcVUFE%3D&st=2019-12-09T23%3A35%3A58Z&se=2019-12-10T07%3A45%3A58Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt\"], [\"logs/azureml/139_azureml.log\"]], \"run_duration\": \"0:00:59\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"2019-12-09 23:45:28,557|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2019-12-09 23:45:28,557|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2019-12-09 23:45:28,564|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2019-12-09 23:45:28,564|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2019-12-09 23:45:28,832|azureml._base_sdk_common.user_agent|DEBUG|Fetching client info from /root/.azureml/clientinfo.json\\n2019-12-09 23:45:28,833|azureml._base_sdk_common.user_agent|DEBUG|Error loading client info: [Errno 2] No such file or directory: '/root/.azureml/clientinfo.json'\\n2019-12-09 23:45:29,245|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7fe835afc268> for run source azureml.scriptrun\\n2019-12-09 23:45:29,246|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2019-12-09 23:45:29,256|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-09 23:45:29,256|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2019-12-09 23:45:29,257|azureml.core.authentication|DEBUG|Time to expire 1814364.74286 seconds\\n2019-12-09 23:45:29,258|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:29,258|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:29,258|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:29,258|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:29,258|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:29,258|azureml._base_sdk_common.service_discovery|DEBUG|Constructing mms service url in from history url environment variable None, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:29,258|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:29,259|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:29,259|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:29,293|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:29,300|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-09 23:45:29,311|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-09 23:45:29,317|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-09 23:45:29,324|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-09 23:45:29,331|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-09 23:45:29,332|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.RunClient.get-async:False|DEBUG|[START]\\n2019-12-09 23:45:29,332|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2019-12-09 23:45:29,332|msrest.http_logger|DEBUG|Request URL: 'https://westus2.experiments.azureml.net/history/v1.0/subscriptions/c5ec24ce-9c5f-4da2-bf12-9ca8e9758d60/resourceGroups/ai-lab/providers/Microsoft.MachineLearningServices/workspaces/ailabml/experiments/ai-lab-defect-detection/runs/ai-lab-defect-detection_1575935091_504b22a6'\\n2019-12-09 23:45:29,333|msrest.http_logger|DEBUG|Request method: 'GET'\\n2019-12-09 23:45:29,333|msrest.http_logger|DEBUG|Request headers:\\n2019-12-09 23:45:29,333|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2019-12-09 23:45:29,333|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2019-12-09 23:45:29,333|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '2b19dcf6-6e19-4aa5-b6db-552993bb47ab'\\n2019-12-09 23:45:29,333|msrest.http_logger|DEBUG|    'request-id': '2b19dcf6-6e19-4aa5-b6db-552993bb47ab'\\n2019-12-09 23:45:29,334|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.2 (Linux-4.15.0-1057-azure-x86_64-with-debian-stretch-sid) msrest/0.6.10 azureml._restclient/core.1.0.76'\\n2019-12-09 23:45:29,334|msrest.http_logger|DEBUG|Request body:\\n2019-12-09 23:45:29,334|msrest.http_logger|DEBUG|None\\n2019-12-09 23:45:29,334|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2019-12-09 23:45:29,334|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2019-12-09 23:45:29,334|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2019-12-09 23:45:29,334|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2019-12-09 23:45:29,433|msrest.http_logger|DEBUG|Response status: 200\\n2019-12-09 23:45:29,434|msrest.http_logger|DEBUG|Response headers:\\n2019-12-09 23:45:29,434|msrest.http_logger|DEBUG|    'Date': 'Mon, 09 Dec 2019 23:45:29 GMT'\\n2019-12-09 23:45:29,435|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2019-12-09 23:45:29,435|msrest.http_logger|DEBUG|    'Transfer-Encoding': 'chunked'\\n2019-12-09 23:45:29,435|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2019-12-09 23:45:29,435|msrest.http_logger|DEBUG|    'Vary': 'Accept-Encoding'\\n2019-12-09 23:45:29,435|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2019-12-09 23:45:29,435|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '2b19dcf6-6e19-4aa5-b6db-552993bb47ab'\\n2019-12-09 23:45:29,435|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2019-12-09 23:45:29,435|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2019-12-09 23:45:29,435|msrest.http_logger|DEBUG|    'X-Content-Type-Options': 'nosniff'\\n2019-12-09 23:45:29,436|msrest.http_logger|DEBUG|    'Content-Encoding': 'gzip'\\n2019-12-09 23:45:29,436|msrest.http_logger|DEBUG|Response content:\\n2019-12-09 23:45:29,436|msrest.http_logger|DEBUG|{\\n  \\\"runNumber\\\": 16,\\n  \\\"rootRunId\\\": \\\"ai-lab-defect-detection_1575935091_504b22a6\\\",\\n  \\\"experimentId\\\": \\\"7977a11f-0ac2-4b79-a7ad-73c7f082e389\\\",\\n  \\\"createdUtc\\\": \\\"2019-12-09T23:44:54.0149503+00:00\\\",\\n  \\\"createdBy\\\": {\\n    \\\"userObjectId\\\": \\\"7c2b1d9f-fb90-4e77-9dc8-b169a2ced3ea\\\",\\n    \\\"userPuId\\\": \\\"1003BFFD95D66411\\\",\\n    \\\"userIdp\\\": null,\\n    \\\"userAltSecId\\\": null,\\n    \\\"userIss\\\": \\\"https://sts.windows.net/72f988bf-86f1-41af-91ab-2d7cd011db47/\\\",\\n    \\\"userTenantId\\\": \\\"72f988bf-86f1-41af-91ab-2d7cd011db47\\\",\\n    \\\"userName\\\": \\\"Alexandre Delarue\\\"\\n  },\\n  \\\"userId\\\": \\\"7c2b1d9f-fb90-4e77-9dc8-b169a2ced3ea\\\",\\n  \\\"token\\\": null,\\n  \\\"tokenExpiryTimeUtc\\\": null,\\n  \\\"error\\\": null,\\n  \\\"warnings\\\": null,\\n  \\\"revision\\\": 6,\\n  \\\"runId\\\": \\\"ai-lab-defect-detection_1575935091_504b22a6\\\",\\n  \\\"parentRunId\\\": null,\\n  \\\"status\\\": \\\"Running\\\",\\n  \\\"startTimeUtc\\\": \\\"2019-12-09T23:45:04.8191144+00:00\\\",\\n  \\\"endTimeUtc\\\": null,\\n  \\\"heartbeatEnabled\\\": false,\\n  \\\"options\\\": {\\n    \\\"generateDataContainerIdIfNotSpecified\\\": true\\n  },\\n  \\\"name\\\": null,\\n  \\\"dataContainerId\\\": \\\"dcid.ai-lab-defect-detection_1575935091_504b22a6\\\",\\n  \\\"description\\\": null,\\n  \\\"hidden\\\": false,\\n  \\\"runType\\\": \\\"azureml.scriptrun\\\",\\n  \\\"properties\\\": {\\n    \\\"_azureml.ComputeTargetType\\\": \\\"amlcompute\\\",\\n    \\\"ContentSnapshotId\\\": \\\"f165d986-5f34-4736-93a8-b571e39c9680\\\",\\n    \\\"AzureML.DerivedImageName\\\": \\\"azureml/azureml_d52ec22a82c6605a7e3742b0f8974fc7\\\",\\n    \\\"ProcessInfoFile\\\": \\\"azureml-logs/process_info.json\\\",\\n    \\\"ProcessStatusFile\\\": \\\"azureml-logs/process_status.json\\\"\\n  },\\n  \\\"scriptName\\\": \\\"train.py\\\",\\n  \\\"target\\\": \\\"cpu-cluster\\\",\\n  \\\"tags\\\": {},\\n  \\\"inputDatasets\\\": [],\\n  \\\"runDefinition\\\": null,\\n  \\\"createdFrom\\\": null,\\n  \\\"cancelUri\\\": \\\"https://westus2.experiments.azureml.net/execution/v1.0/subscriptions/c5ec24ce-9c5f-4da2-bf12-9ca8e9758d60/resourceGroups/ai-lab/providers/Microsoft.MachineLearningServices/workspaces/ailabml/experiments/ai-lab-defect-detection/runId/ai-lab-defect-detection_1575935091_504b22a6/cancel\\\",\\n  \\\"completeUri\\\": null,\\n  \\\"diagnosticsUri\\\": \\\"https://westus2.experiments.azureml.net/execution/v1.0/subscriptions/c5ec24ce-9c5f-4da2-bf12-9ca8e9758d60/resourceGroups/ai-lab/providers/Microsoft.MachineLearningServices/workspaces/ailabml/experiments/ai-lab-defect-detection/runId/ai-lab-defect-detection_1575935091_504b22a6/diagnostics\\\",\\n  \\\"computeRequest\\\": {\\n    \\\"nodeCount\\\": 1\\n  },\\n  \\\"retainForLifetimeOfWorkspace\\\": false\\n}\\n2019-12-09 23:45:29,443|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.RunClient.get-async:False|DEBUG|[STOP]\\n2019-12-09 23:45:29,444|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'f165d986-5f34-4736-93a8-b571e39c9680', 'AzureML.DerivedImageName': 'azureml/azureml_d52ec22a82c6605a7e3742b0f8974fc7', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2019-12-09 23:45:29,444|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2019-12-09 23:45:29,444|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2019-12-09 23:45:29,445|azureml.WorkerPool|DEBUG|[START]\\n2019-12-09 23:45:29,445|azureml.SendRunKillSignal|DEBUG|[START]\\n2019-12-09 23:45:29,445|azureml.RunStatusContext|DEBUG|[START]\\n2019-12-09 23:45:29,445|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunContextManager.RunStatusContext|DEBUG|[START]\\n2019-12-09 23:45:29,445|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2019-12-09 23:45:29,445|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2019-12-09 23:45:29,445|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/ailabml/azureml/ai-lab-defect-detection_1575935091_504b22a6/mounts/workspaceblobstore/azureml/ai-lab-defect-detection_1575935091_504b22a6\\n2019-12-09 23:45:29,446|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2019-12-09 23:45:29,446|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/ailabml/azureml/ai-lab-defect-detection_1575935091_504b22a6/mounts/workspaceblobstore/azureml/ai-lab-defect-detection_1575935091_504b22a6\\n2019-12-09 23:45:30,811|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:30,812|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:30,812|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:30,812|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:30,812|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:30,812|azureml._base_sdk_common.service_discovery|DEBUG|Constructing mms service url in from history url environment variable None, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:30,812|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:30,813|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:30,813|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.experiments.azureml.net.\\n2019-12-09 23:45:30,821|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-09 23:45:30,822|azureml._run_impl.run_history_facade|DEBUG|Created a static thread pool for RunHistoryFacade class\\n2019-12-09 23:45:30,828|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-09 23:45:30,835|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-09 23:45:30,842|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-09 23:45:30,850|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-09 23:45:30,850|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.RunClient.get-async:False|DEBUG|[START]\\n2019-12-09 23:45:30,851|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2019-12-09 23:45:30,851|msrest.http_logger|DEBUG|Request URL: 'https://westus2.experiments.azureml.net/history/v1.0/subscriptions/c5ec24ce-9c5f-4da2-bf12-9ca8e9758d60/resourceGroups/ai-lab/providers/Microsoft.MachineLearningServices/workspaces/ailabml/experiments/ai-lab-defect-detection/runs/ai-lab-defect-detection_1575935091_504b22a6'\\n2019-12-09 23:45:30,852|msrest.http_logger|DEBUG|Request method: 'GET'\\n2019-12-09 23:45:30,852|msrest.http_logger|DEBUG|Request headers:\\n2019-12-09 23:45:30,852|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2019-12-09 23:45:30,852|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2019-12-09 23:45:30,852|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '0284278d-9868-4e82-80ef-089d04a283a8'\\n2019-12-09 23:45:30,852|msrest.http_logger|DEBUG|    'request-id': '0284278d-9868-4e82-80ef-089d04a283a8'\\n2019-12-09 23:45:30,852|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.2 (Linux-4.15.0-1057-azure-x86_64-with-debian-stretch-sid) msrest/0.6.10 azureml._restclient/core.1.0.76'\\n2019-12-09 23:45:30,853|msrest.http_logger|DEBUG|Request body:\\n2019-12-09 23:45:30,853|msrest.http_logger|DEBUG|None\\n2019-12-09 23:45:30,853|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2019-12-09 23:45:30,853|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2019-12-09 23:45:30,853|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2019-12-09 23:45:30,853|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2019-12-09 23:45:30,925|msrest.http_logger|DEBUG|Response status: 200\\n2019-12-09 23:45:30,925|msrest.http_logger|DEBUG|Response headers:\\n2019-12-09 23:45:30,925|msrest.http_logger|DEBUG|    'Date': 'Mon, 09 Dec 2019 23:45:30 GMT'\\n2019-12-09 23:45:30,925|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2019-12-09 23:45:30,926|msrest.http_logger|DEBUG|    'Transfer-Encoding': 'chunked'\\n2019-12-09 23:45:30,926|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2019-12-09 23:45:30,926|msrest.http_logger|DEBUG|    'Vary': 'Accept-Encoding'\\n2019-12-09 23:45:30,926|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2019-12-09 23:45:30,926|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '0284278d-9868-4e82-80ef-089d04a283a8'\\n2019-12-09 23:45:30,926|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2019-12-09 23:45:30,926|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2019-12-09 23:45:30,926|msrest.http_logger|DEBUG|    'X-Content-Type-Options': 'nosniff'\\n2019-12-09 23:45:30,926|msrest.http_logger|DEBUG|    'Content-Encoding': 'gzip'\\n2019-12-09 23:45:30,926|msrest.http_logger|DEBUG|Response content:\\n2019-12-09 23:45:30,927|msrest.http_logger|DEBUG|{\\n  \\\"runNumber\\\": 16,\\n  \\\"rootRunId\\\": \\\"ai-lab-defect-detection_1575935091_504b22a6\\\",\\n  \\\"experimentId\\\": \\\"7977a11f-0ac2-4b79-a7ad-73c7f082e389\\\",\\n  \\\"createdUtc\\\": \\\"2019-12-09T23:44:54.0149503+00:00\\\",\\n  \\\"createdBy\\\": {\\n    \\\"userObjectId\\\": \\\"7c2b1d9f-fb90-4e77-9dc8-b169a2ced3ea\\\",\\n    \\\"userPuId\\\": \\\"1003BFFD95D66411\\\",\\n    \\\"userIdp\\\": null,\\n    \\\"userAltSecId\\\": null,\\n    \\\"userIss\\\": \\\"https://sts.windows.net/72f988bf-86f1-41af-91ab-2d7cd011db47/\\\",\\n    \\\"userTenantId\\\": \\\"72f988bf-86f1-41af-91ab-2d7cd011db47\\\",\\n    \\\"userName\\\": \\\"Alexandre Delarue\\\"\\n  },\\n  \\\"userId\\\": \\\"7c2b1d9f-fb90-4e77-9dc8-b169a2ced3ea\\\",\\n  \\\"token\\\": null,\\n  \\\"tokenExpiryTimeUtc\\\": null,\\n  \\\"error\\\": null,\\n  \\\"warnings\\\": null,\\n  \\\"revision\\\": 6,\\n  \\\"runId\\\": \\\"ai-lab-defect-detection_1575935091_504b22a6\\\",\\n  \\\"parentRunId\\\": null,\\n  \\\"status\\\": \\\"Running\\\",\\n  \\\"startTimeUtc\\\": \\\"2019-12-09T23:45:04.8191144+00:00\\\",\\n  \\\"endTimeUtc\\\": null,\\n  \\\"heartbeatEnabled\\\": false,\\n  \\\"options\\\": {\\n    \\\"generateDataContainerIdIfNotSpecified\\\": true\\n  },\\n  \\\"name\\\": null,\\n  \\\"dataContainerId\\\": \\\"dcid.ai-lab-defect-detection_1575935091_504b22a6\\\",\\n  \\\"description\\\": null,\\n  \\\"hidden\\\": false,\\n  \\\"runType\\\": \\\"azureml.scriptrun\\\",\\n  \\\"properties\\\": {\\n    \\\"_azureml.ComputeTargetType\\\": \\\"amlcompute\\\",\\n    \\\"ContentSnapshotId\\\": \\\"f165d986-5f34-4736-93a8-b571e39c9680\\\",\\n    \\\"AzureML.DerivedImageName\\\": \\\"azureml/azureml_d52ec22a82c6605a7e3742b0f8974fc7\\\",\\n    \\\"ProcessInfoFile\\\": \\\"azureml-logs/process_info.json\\\",\\n    \\\"ProcessStatusFile\\\": \\\"azureml-logs/process_status.json\\\"\\n  },\\n  \\\"scriptName\\\": \\\"train.py\\\",\\n  \\\"target\\\": \\\"cpu-cluster\\\",\\n  \\\"tags\\\": {},\\n  \\\"inputDatasets\\\": [],\\n  \\\"runDefinition\\\": null,\\n  \\\"createdFrom\\\": null,\\n  \\\"cancelUri\\\": \\\"https://westus2.experiments.azureml.net/execution/v1.0/subscriptions/c5ec24ce-9c5f-4da2-bf12-9ca8e9758d60/resourceGroups/ai-lab/providers/Microsoft.MachineLearningServices/workspaces/ailabml/experiments/ai-lab-defect-detection/runId/ai-lab-defect-detection_1575935091_504b22a6/cancel\\\",\\n  \\\"completeUri\\\": null,\\n  \\\"diagnosticsUri\\\": \\\"https://westus2.experiments.azureml.net/execution/v1.0/subscriptions/c5ec24ce-9c5f-4da2-bf12-9ca8e9758d60/resourceGroups/ai-lab/providers/Microsoft.MachineLearningServices/workspaces/ailabml/experiments/ai-lab-defect-detection/runId/ai-lab-defect-detection_1575935091_504b22a6/diagnostics\\\",\\n  \\\"computeRequest\\\": {\\n    \\\"nodeCount\\\": 1\\n  },\\n  \\\"retainForLifetimeOfWorkspace\\\": false\\n}\\n2019-12-09 23:45:30,928|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.RunClient.get-async:False|DEBUG|[STOP]\\n2019-12-09 23:45:30,929|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'f165d986-5f34-4736-93a8-b571e39c9680', 'AzureML.DerivedImageName': 'azureml/azureml_d52ec22a82c6605a7e3742b0f8974fc7', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2019-12-09 23:45:30,929|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2019-12-09 23:45:30,985|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2019-12-09 23:45:30,986|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/ailabml/azureml/ai-lab-defect-detection_1575935091_504b22a6/mounts/workspaceblobstore/azureml/ai-lab-defect-detection_1575935091_504b22a6\\n2019-12-09 23:45:30,986|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/ailabml/azureml/ai-lab-defect-detection_1575935091_504b22a6/mounts/workspaceblobstore/azureml/ai-lab-defect-detection_1575935091_504b22a6 to /mnt/batch/tasks/shared/LS_root/jobs/ailabml/azureml/ai-lab-defect-detection_1575935091_504b22a6/mounts/workspaceblobstore/azureml/ai-lab-defect-detection_1575935091_504b22a6\\n2019-12-09 23:45:30,986|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/ailabml/azureml/ai-lab-defect-detection_1575935091_504b22a6/mounts/workspaceblobstore/azureml/ai-lab-defect-detection_1575935091_504b22a6\\n2019-12-09 23:45:30,986|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2019-12-09 23:45:30,986|azureml.WorkingDirectoryCM|ERROR|<class 'KeyError'>: 'Light Bulbs-2019-12-08 00:35:33'\\n<traceback object at 0x7fe812478608>\\n2019-12-09 23:45:30,986|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2019-12-09 23:45:30,986|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6|INFO|fail is not setting status for submitted runs.\\n2019-12-09 23:45:30,987|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2019-12-09 23:45:30,987|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2019-12-09 23:45:30,987|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2019-12-09 23:45:30,987|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2019-12-09 23:45:30,988|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2019-12-09 23:45:30,988|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2019-12-09 23:45:30,988|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2019-12-09 23:45:30,988|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2019-12-09 23:45:30,988|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2019-12-09 23:45:30,988|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2019-12-09 23:45:30,989|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.RunClient.post-async:False|DEBUG|[START]\\n2019-12-09 23:45:30,989|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2019-12-09 23:45:30,989|msrest.http_logger|DEBUG|Request URL: 'https://westus2.experiments.azureml.net/history/v1.0/subscriptions/c5ec24ce-9c5f-4da2-bf12-9ca8e9758d60/resourceGroups/ai-lab/providers/Microsoft.MachineLearningServices/workspaces/ailabml/experiments/ai-lab-defect-detection/runs/ai-lab-defect-detection_1575935091_504b22a6/events'\\n2019-12-09 23:45:30,990|msrest.http_logger|DEBUG|Request method: 'POST'\\n2019-12-09 23:45:30,990|msrest.http_logger|DEBUG|Request headers:\\n2019-12-09 23:45:30,990|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2019-12-09 23:45:30,990|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2019-12-09 23:45:30,990|msrest.http_logger|DEBUG|    'x-ms-caller-name': 'RunHistoryFacade'\\n2019-12-09 23:45:30,990|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '07b87127-7dde-485c-b09b-c9dc614e1066'\\n2019-12-09 23:45:30,990|msrest.http_logger|DEBUG|    'request-id': '07b87127-7dde-485c-b09b-c9dc614e1066'\\n2019-12-09 23:45:30,990|msrest.http_logger|DEBUG|    'Content-Length': '1619'\\n2019-12-09 23:45:30,990|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.2 (Linux-4.15.0-1057-azure-x86_64-with-debian-stretch-sid) msrest/0.6.10 azureml._restclient/core.1.0.76'\\n2019-12-09 23:45:30,990|msrest.http_logger|DEBUG|Request body:\\n2019-12-09 23:45:30,990|msrest.http_logger|DEBUG|{\\\"timestamp\\\": \\\"2019-12-09T23:45:30.988892Z\\\", \\\"name\\\": \\\"Microsoft.MachineLearning.Run.Error\\\", \\\"data\\\": {\\\"RunId\\\": \\\"ai-lab-defect-detection_1575935091_504b22a6\\\", \\\"ErrorResponse\\\": {\\\"error\\\": {\\\"code\\\": \\\"UserError\\\", \\\"message\\\": \\\"User program failed with KeyError: 'Light Bulbs-2019-12-08 00:35:33'\\\", \\\"detailsUri\\\": \\\"https://aka.ms/azureml-known-errors\\\", \\\"debugInfo\\\": {\\\"type\\\": \\\"KeyError\\\", \\\"message\\\": \\\"'Light Bulbs-2019-12-08 00:35:33'\\\", \\\"stackTrace\\\": \\\"  File \\\\\\\"/mnt/batch/tasks/shared/LS_root/jobs/ailabml/azureml/ai-lab-defect-detection_1575935091_504b22a6/mounts/workspaceblobstore/azureml/ai-lab-defect-detection_1575935091_504b22a6/azureml-setup/context_manager_injector.py\\\\\\\", line 115, in execute_with_context\\\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\\\\\"__main__\\\\\\\")\\\\n  File \\\\\\\"/azureml-envs/azureml_5c4933d61061335bbcb722cd0871730e/lib/python3.6/runpy.py\\\\\\\", line 263, in run_path\\\\n    pkg_name=pkg_name, script_name=fname)\\\\n  File \\\\\\\"/azureml-envs/azureml_5c4933d61061335bbcb722cd0871730e/lib/python3.6/runpy.py\\\\\\\", line 96, in _run_module_code\\\\n    mod_name, mod_spec, pkg_name, script_name)\\\\n  File \\\\\\\"/azureml-envs/azureml_5c4933d61061335bbcb722cd0871730e/lib/python3.6/runpy.py\\\\\\\", line 85, in _run_code\\\\n    exec(code, run_globals)\\\\n  File \\\\\\\"train.py\\\\\\\", line 71, in <module>\\\\n    image_dataset = load_image_files()\\\\n  File \\\\\\\"train.py\\\\\\\", line 24, in load_image_files\\\\n    ds = run.input_datasets['Light Bulbs-2019-12-08 00:35:33']\\\\n  File \\\\\\\"/azureml-envs/azureml_5c4933d61061335bbcb722cd0871730e/lib/python3.6/site-packages/azureml/core/run.py\\\\\\\", line 2205, in __getitem__\\\\n    return super().__getitem__(key)\\\\n\\\"}}}}}\\n2019-12-09 23:45:30,991|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2019-12-09 23:45:30,991|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2019-12-09 23:45:30,991|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2019-12-09 23:45:30,991|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2019-12-09 23:45:31,130|msrest.http_logger|DEBUG|Response status: 200\\n2019-12-09 23:45:31,130|msrest.http_logger|DEBUG|Response headers:\\n2019-12-09 23:45:31,131|msrest.http_logger|DEBUG|    'Date': 'Mon, 09 Dec 2019 23:45:31 GMT'\\n2019-12-09 23:45:31,131|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2019-12-09 23:45:31,131|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2019-12-09 23:45:31,131|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2019-12-09 23:45:31,131|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '07b87127-7dde-485c-b09b-c9dc614e1066'\\n2019-12-09 23:45:31,131|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2019-12-09 23:45:31,131|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2019-12-09 23:45:31,131|msrest.http_logger|DEBUG|    'X-Content-Type-Options': 'nosniff'\\n2019-12-09 23:45:31,131|msrest.http_logger|DEBUG|Response content:\\n2019-12-09 23:45:31,132|msrest.http_logger|DEBUG|\\n2019-12-09 23:45:31,133|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.RunClient.post-async:False|DEBUG|[STOP]\\n2019-12-09 23:45:31,133|azureml.RunStatusContext|ERROR|<class 'KeyError'>: 'Light Bulbs-2019-12-08 00:35:33'\\n<traceback object at 0x7fe812478608>\\n2019-12-09 23:45:31,134|azureml.RunStatusContext|DEBUG|[STOP]\\n2019-12-09 23:45:31,134|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2019-12-09 23:45:31,134|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2019-12-09 23:45:31,134|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2019-12-09 23:45:31,134|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [].\\n2019-12-09 23:45:31,134|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2019-12-09 23:45:31,134|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2019-12-09 23:45:31,134|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2019-12-09 23:45:31,135|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2019-12-09 23:45:31,135|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2019-12-09 23:45:31,135|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2019-12-09 23:45:31,135|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2019-12-09 23:45:31,136|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2019-12-09 23:45:31,136|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2019-12-09 23:45:31,136|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [].\\n2019-12-09 23:45:31,136|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2019-12-09 23:45:31,136|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2019-12-09 23:45:31,136|azureml._SubmittedRun#ai-lab-defect-detection_1575935091_504b22a6.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2019-12-09 23:45:31,136|azureml.SendRunKillSignal|ERROR|<class 'KeyError'>: 'Light Bulbs-2019-12-08 00:35:33'\\n<traceback object at 0x7fe812478608>\\n2019-12-09 23:45:31,136|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2019-12-09 23:45:31,137|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2019-12-09 23:45:31,137|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2019-12-09 23:45:31,137|azureml.WorkerPool|ERROR|<class 'KeyError'>: 'Light Bulbs-2019-12-08 00:35:33'\\n<traceback object at 0x7fe812478608>\\n2019-12-09 23:45:31,137|azureml.WorkerPool|DEBUG|[STOP]\\n\\nError occurred: User program failed with KeyError: 'Light Bulbs-2019-12-08 00:35:33'\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"NOTSET\", \"sdk_version\": \"1.0.76\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, if you need to cancel a run, you can follow [these instructions](https://aka.ms/aml-docs-cancel-run)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get log results upon completion\n",
    "\n",
    "Model training happens in the background. You can use `wait_for_completion` to block and wait until the model has completed training before running more code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": [
     "remote run",
     "amlcompute",
     "scikit-learn"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: ai-lab-defect-detection_1575932264_871d14da\n",
      "Web View: https://ml.azure.com/experiments/ai-lab-defect-detection/runs/ai-lab-defect-detection_1575932264_871d14da?wsid=/subscriptions/c5ec24ce-9c5f-4da2-bf12-9ca8e9758d60/resourcegroups/ai-lab/workspaces/ailabml\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2019-12-09T22:57:59Z Starting output-watcher...\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_d52ec22a82c6605a7e3742b0f8974fc7\n",
      "Digest: sha256:dfde58f8b2c9e723ae24827302ac963776c6b0320bf10d83c5a8e5696e133be6\n",
      "Status: Image is up to date for ailabml1b51bd50.azurecr.io/azureml/azureml_d52ec22a82c6605a7e3742b0f8974fc7:latest\n",
      "162dd4ef4b846bc8a9dbd8d9c1cf7dc133fc343e67c48ae7ded1af606d3e6888\n",
      "2019/12/09 22:58:02 Version: 3.0.01059.0002 Branch: master Commit: e8f402a4\n",
      "2019/12/09 22:58:02 sshd runtime has already been installed in the container\n",
      "ssh-keygen: /azureml-envs/azureml_5c4933d61061335bbcb722cd0871730e/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_5c4933d61061335bbcb722cd0871730e/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "bash: /azureml-envs/azureml_5c4933d61061335bbcb722cd0871730e/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "bash: /azureml-envs/azureml_5c4933d61061335bbcb722cd0871730e/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "bash: /azureml-envs/azureml_5c4933d61061335bbcb722cd0871730e/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Starting job preparation. Current time:2019-12-09T22:58:12.794787\n",
      "Extracting the control code.\n",
      "Creating directory: azureml-logs/\n",
      "Retrieving project from URI: https://ailabml2830329216.blob.core.windows.net/azureml-blobstore-b380e1ef-30a1-4229-b1f6-236b66b5902b/azureml/project_zip_fd06f02ce889401f8fbe24d6b9e75c78?sv=2019-02-02&sr=b&sig=PN6EqmFJvWbN6HLkrZ%2BmXmA1eatvab2eR3G9PW9CVMA%3D&st=2019-12-09T22%3A47%3A46Z&se=2019-12-16T22%3A57%3A46Z&sp=r\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "bash: /azureml-envs/azureml_5c4933d61061335bbcb722cd0871730e/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "bash: /azureml-envs/azureml_5c4933d61061335bbcb722cd0871730e/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 140\n",
      "Entering Run History Context Manager.\n",
      "/azureml-envs/azureml_5c4933d61061335bbcb722cd0871730e/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "MSI: Failed to retrieve a token from 'http://172.17.0.1:35569/MSI/token//?resource=https://management.core.windows.net/&api-version=2017-09-01' with an error of 'HTTPConnectionPool(host='172.17.0.1', port=35569): Max retries exceeded with url: /MSI/token//?resource=https://management.core.windows.net/&api-version=2017-09-01 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6561db5748>: Failed to establish a new connection: [Errno 111] Connection refused',))'.\n",
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code BBHBT6RS3 to authenticate.\n",
      "Interactive authentication successfully completed.\n",
      "\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]\n",
      "  3%|▎         | 1/34 [00:00<00:21,  1.57it/s]\n",
      "  6%|▌         | 2/34 [00:00<00:16,  2.00it/s]\n",
      "  9%|▉         | 3/34 [00:02<00:27,  1.15it/s]\n",
      " 12%|█▏        | 4/34 [00:02<00:21,  1.38it/s]\n",
      " 15%|█▍        | 5/34 [00:03<00:17,  1.67it/s]\n",
      " 18%|█▊        | 6/34 [00:03<00:12,  2.19it/s]\n",
      " 21%|██        | 7/34 [00:03<00:09,  2.77it/s]\n",
      " 24%|██▎       | 8/34 [00:03<00:07,  3.37it/s]\n",
      " 26%|██▋       | 9/34 [00:03<00:06,  4.05it/s]\n",
      " 29%|██▉       | 10/34 [00:03<00:05,  4.64it/s]\n",
      " 32%|███▏      | 11/34 [00:04<00:09,  2.41it/s]\n",
      " 35%|███▌      | 12/34 [00:04<00:07,  3.07it/s]\n",
      " 38%|███▊      | 13/34 [00:05<00:05,  3.87it/s]\n",
      " 41%|████      | 14/34 [00:05<00:05,  3.49it/s]\n",
      " 44%|████▍     | 15/34 [00:05<00:05,  3.76it/s]\n",
      " 47%|████▋     | 16/34 [00:05<00:05,  3.27it/s]\n",
      " 50%|█████     | 17/34 [00:06<00:04,  3.90it/s]\n",
      " 53%|█████▎    | 18/34 [00:06<00:03,  4.42it/s]\n",
      " 56%|█████▌    | 19/34 [00:07<00:06,  2.37it/s]\n",
      " 59%|█████▉    | 20/34 [00:07<00:05,  2.60it/s]\n",
      " 62%|██████▏   | 21/34 [00:07<00:03,  3.34it/s]\n",
      " 65%|██████▍   | 22/34 [00:07<00:02,  4.14it/s]\n",
      " 68%|██████▊   | 23/34 [00:07<00:02,  4.88it/s]\n",
      " 71%|███████   | 24/34 [00:09<00:06,  1.47it/s]\n",
      " 74%|███████▎  | 25/34 [00:10<00:06,  1.36it/s]\n",
      " 79%|███████▉  | 27/34 [00:10<00:03,  1.83it/s]\n",
      " 82%|████████▏ | 28/34 [00:10<00:02,  2.41it/s]\n",
      " 85%|████████▌ | 29/34 [00:10<00:01,  2.83it/s]\n",
      " 88%|████████▊ | 30/34 [00:11<00:01,  3.34it/s]\n",
      " 91%|█████████ | 31/34 [00:11<00:01,  2.95it/s]\n",
      " 94%|█████████▍| 32/34 [00:12<00:00,  2.42it/s]\n",
      " 97%|█████████▋| 33/34 [00:12<00:00,  2.99it/s]\n",
      "100%|██████████| 34/34 [00:12<00:00,  2.74it/s]\n",
      "(27, 65536)\n",
      "(27,)\n",
      "(7, 65536)\n",
      "(7,)\n",
      "Train a logistic regression model with regularization rate of 0.5\n",
      "Predict the test set\n",
      "Classification report for - \n",
      "LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=12, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      broken       0.67      0.67      0.67         3\n",
      "  not_broken       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.71         7\n",
      "   macro avg       0.71      0.71      0.71         7\n",
      "weighted avg       0.71      0.71      0.71         7\n",
      "\n",
      "\n",
      "Accuracy is 0.7142857142857143\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "bash: /azureml-envs/azureml_5c4933d61061335bbcb722cd0871730e/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Starting job release. Current time:2019-12-09T23:03:42.768172\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 1300\n",
      "Job release is complete. Current time:2019-12-09T23:03:51.009266\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: ai-lab-defect-detection_1575932264_871d14da\n",
      "Web View: https://ml.azure.com/experiments/ai-lab-defect-detection/runs/ai-lab-defect-detection_1575932264_871d14da?wsid=/subscriptions/c5ec24ce-9c5f-4da2-bf12-9ca8e9758d60/resourcegroups/ai-lab/workspaces/ailabml\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'ai-lab-defect-detection_1575932264_871d14da',\n",
       " 'target': 'cpu-cluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2019-12-09T22:58:12.11497Z',\n",
       " 'endTimeUtc': '2019-12-09T23:04:05.514823Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'a769a3cc-b42c-409c-83cb-ce3c2e316dec',\n",
       "  'AzureML.DerivedImageName': 'azureml/azureml_d52ec22a82c6605a7e3742b0f8974fc7',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '9fe4e0e6-c822-4ab9-8d87-9d6623a99715'}, 'consumptionDetails': {'type': 'Reference'}}],\n",
       " 'runDefinition': {'script': 'train.py',\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'cpu-cluster',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'my_env',\n",
       "   'version': 'Autosave_2019-12-09T21:47:28Z_c7e96913',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-contrib-dataset==1.0.76.*',\n",
       "        'azureml-core==1.0.76.*',\n",
       "        'azureml-dataprep[pandas,fuse]',\n",
       "        'azureml-dataprep-native',\n",
       "        'numpy',\n",
       "        'pandas',\n",
       "        'scikit-image',\n",
       "        'scikit-learn',\n",
       "        'sklearn',\n",
       "        'tqdm']}],\n",
       "     'name': 'azureml_5c4933d61061335bbcb722cd0871730e'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt': 'https://ailabml2830329216.blob.core.windows.net/azureml/ExperimentRun/dcid.ai-lab-defect-detection_1575932264_871d14da/azureml-logs/55_azureml-execution-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt?sv=2019-02-02&sr=b&sig=4KzwQWBbkly59vfA3LvzeXvVq9CrISan5IRZKZmYtSw%3D&st=2019-12-09T22%3A54%3A06Z&se=2019-12-10T07%3A04%3A06Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt': 'https://ailabml2830329216.blob.core.windows.net/azureml/ExperimentRun/dcid.ai-lab-defect-detection_1575932264_871d14da/azureml-logs/65_job_prep-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt?sv=2019-02-02&sr=b&sig=XvdRWJ%2Fo7Q%2FftT%2FPRyybNy70DOEm%2FxVwHA7nPki44mc%3D&st=2019-12-09T22%3A54%3A06Z&se=2019-12-10T07%3A04%3A06Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://ailabml2830329216.blob.core.windows.net/azureml/ExperimentRun/dcid.ai-lab-defect-detection_1575932264_871d14da/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=lk1sPRCIm0eWQIGLwJZkqmQli82uMhS83nXVI85YeyM%3D&st=2019-12-09T22%3A54%3A06Z&se=2019-12-10T07%3A04%3A06Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt': 'https://ailabml2830329216.blob.core.windows.net/azureml/ExperimentRun/dcid.ai-lab-defect-detection_1575932264_871d14da/azureml-logs/75_job_post-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt?sv=2019-02-02&sr=b&sig=Qw5lqyCSWnetlPg0tI1FoDI8w4E%2B7GS5ZmoNAtzPCeU%3D&st=2019-12-09T22%3A54%3A06Z&se=2019-12-10T07%3A04%3A06Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://ailabml2830329216.blob.core.windows.net/azureml/ExperimentRun/dcid.ai-lab-defect-detection_1575932264_871d14da/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=n9qCttMFet4rKYpFR7u3lz5wlirGPVHbv9czutQvBvI%3D&st=2019-12-09T22%3A54%3A06Z&se=2019-12-10T07%3A04%3A06Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://ailabml2830329216.blob.core.windows.net/azureml/ExperimentRun/dcid.ai-lab-defect-detection_1575932264_871d14da/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=zyjiZ%2FLLASOEeAwJ6JjFKs76sez51DnFZpyMqBAAQPI%3D&st=2019-12-09T22%3A54%3A06Z&se=2019-12-10T07%3A04%3A06Z&sp=r',\n",
       "  'logs/azureml/140_azureml.log': 'https://ailabml2830329216.blob.core.windows.net/azureml/ExperimentRun/dcid.ai-lab-defect-detection_1575932264_871d14da/logs/azureml/140_azureml.log?sv=2019-02-02&sr=b&sig=HxOj4GtgjyFmdgEdk%2Bo%2FNiEYSdOreBnfKnUWzf19sns%3D&st=2019-12-09T22%3A54%3A06Z&se=2019-12-10T07%3A04%3A06Z&sp=r',\n",
       "  'logs/azureml/azureml.log': 'https://ailabml2830329216.blob.core.windows.net/azureml/ExperimentRun/dcid.ai-lab-defect-detection_1575932264_871d14da/logs/azureml/azureml.log?sv=2019-02-02&sr=b&sig=MEpY0SqxxjadTwvO%2B2Opz5arjeYV1hs0qqTqZ5vv%2Few%3D&st=2019-12-09T22%3A54%3A06Z&se=2019-12-10T07%3A04%3A06Z&sp=r'}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify show_output to True for a verbose log\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display run results\n",
    "\n",
    "You now have a model trained on a remote cluster.  Retrieve all the metrics logged during the run, including the accuracy of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": [
     "get metrics"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regularization rate': 0.5, 'accuracy': 0.7142857142857143}\n"
     ]
    }
   ],
   "source": [
    "print(run.get_metrics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next tutorial you will explore this model in more detail.\n",
    "\n",
    "## Register model\n",
    "\n",
    "The last step in the training script wrote the file `outputs/sklearn_mnist_model.pkl` in a directory named `outputs` in the VM of the cluster where the job is executed. `outputs` is a special directory in that all content in this  directory is automatically uploaded to your workspace.  This content appears in the run record in the experiment under your workspace. Hence, the model file is now also available in your workspace.\n",
    "\n",
    "You can see files associated with that run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": [
     "query history"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['azureml-logs/55_azureml-execution-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt', 'azureml-logs/65_job_prep-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt', 'azureml-logs/70_driver_log.txt', 'azureml-logs/75_job_post-tvmps_39d9b49377e7c2f7513f5ce018114dd8d0f090f1f1e67efbee48e059809e9e8e_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/140_azureml.log', 'logs/azureml/azureml.log', 'outputs/ai_lab_defect_detection_model.pkl']\n"
     ]
    }
   ],
   "source": [
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the model in the workspace so that you (or other collaborators) can later query, examine, and deploy this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": [
     "register model from history"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai_lab_defect_detection\tai_lab_defect_detection:4\t4\n"
     ]
    }
   ],
   "source": [
    "# register model \n",
    "model = run.register_model(model_name='ai_lab_defect_detection', model_path='outputs/ai_lab_defect_detection_model.pkl')\n",
    "print(model.name, model.id, model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "In this Azure Machine Learning tutorial, you used Python to:\n",
    "\n",
    "> * Set up your development environment\n",
    "> * Access and examine the data\n",
    "> * Train multiple models on a remote cluster using the popular scikit-learn machine learning library\n",
    "> * Review training details and register the best model\n",
    "\n",
    "You are ready to deploy this registered model using the instructions in the next part of the tutorial series:\n",
    "\n",
    "> [Tutorial 2 - Deploy models](img-classification-part2-deploy.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/tutorials/img-classification-part1-training.png)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "maxluk"
   }
  ],
  "categories": [
   "tutorials"
  ],
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "msauthor": "roastala",
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
